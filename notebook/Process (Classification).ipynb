{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:23:31.063766Z",
     "start_time": "2020-10-18T10:23:30.539639Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, tree, ensemble, svm, neighbors\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:23:31.090953Z",
     "start_time": "2020-10-18T10:23:31.067828Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:24:03.576833Z",
     "start_time": "2020-10-18T10:24:03.548856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=223)\n",
    "print('X.shape: ',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:24:53.464268Z",
     "start_time": "2020-10-18T10:24:53.458024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([497, 503]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:26:23.771069Z",
     "start_time": "2020-10-18T10:26:23.764940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (700, 10)\n",
      "x_test.shape:  (300, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "\n",
    "print('x_train.shape: ',x_train.shape)\n",
    "print('x_test.shape: ',x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T09:08:43.139796Z",
     "start_time": "2020-10-18T09:08:43.099791Z"
    }
   },
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:32:08.083611Z",
     "start_time": "2020-10-18T10:32:08.077890Z"
    }
   },
   "outputs": [],
   "source": [
    "ols = linear_model.LogisticRegression()\n",
    "ridge = linear_model.RidgeClassifier(random_state=seed)\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(random_state=seed)\n",
    "rf = ensemble.RandomForestClassifier(random_state=seed)\n",
    "ada = ensemble.AdaBoostClassifier(random_state=seed)\n",
    "gt = ensemble.GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "svc = svm.SVC(probability=True)\n",
    "knn = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:32:09.593774Z",
     "start_time": "2020-10-18T10:32:09.407262Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaehyuk/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jaehyuk/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/jaehyuk/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols.fit(x_train,y_train)\n",
    "ridge.fit(x_train,y_train)\n",
    "\n",
    "dt.fit(x_train,y_train)\n",
    "rf.fit(x_train,y_train)\n",
    "ada.fit(x_train,y_train)\n",
    "gt.fit(x_train,y_train)\n",
    "\n",
    "svc.fit(x_train,y_train)\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:37:22.916602Z",
     "start_time": "2020-10-18T10:37:22.899391Z"
    }
   },
   "outputs": [],
   "source": [
    "ols_prob = ols.predict_proba(x_test)[:,1]\n",
    "ridge_prob = ridge.predict(x_test)\n",
    "\n",
    "dt_prob = dt.predict_proba(x_test)[:,1]\n",
    "rf_prob = rf.predict_proba(x_test)[:,1]\n",
    "ada_prob = ada.predict_proba(x_test)[:,1]\n",
    "gt_prob = gt.predict_proba(x_test)[:,1]\n",
    "\n",
    "svc_prob = svc.predict_proba(x_test)[:,1]\n",
    "knn_prob = knn.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:39:29.391660Z",
     "start_time": "2020-10-18T10:39:29.385542Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = ['ols','ridge','dt','rf','ada','gt','svc','knn']\n",
    "model = [ols, ridge, dt, rf, ada, gt, svc, knn]\n",
    "prob_lst = [ols_prob, ridge_prob, dt_prob, rf_prob, ada_prob, gt_prob, svc_prob, knn_prob]\n",
    "pred_lst = [list(map(int, prob > 0.5)) for prob in prob_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:50:32.164024Z",
     "start_time": "2020-10-18T10:50:32.158260Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_eval(y_true, y_pred, y_prob):\n",
    "    acc = round(metrics.accuracy_score(y_true, y_pred), 3)\n",
    "    precision = round(metrics.precision_score(y_true, y_pred), 3)\n",
    "    recall = round(metrics.recall_score(y_true, y_pred), 3)\n",
    "    f1_score = round(metrics.f1_score(y_true, y_pred), 3)\n",
    "    auc = round(metrics.roc_auc_score(y_true, y_prob), 3)\n",
    "    \n",
    "    return acc, precision, recall, f1_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T11:08:34.968592Z",
     "start_time": "2020-10-18T11:08:34.941658Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(dict([model_name[i],model_eval(y_test, pred_lst[i], prob_lst[i])] for i in range(len(model_name))),\n",
    "                       index=['Accuracy','Precision','Recall','F1_score','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T11:08:35.175663Z",
     "start_time": "2020-10-18T11:08:35.145072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ols</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ridge</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>svc</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dt</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ada</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>knn</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy  Precision  Recall  F1_score    AUC\n",
       "ols       0.963      0.936   0.985     0.960  0.985\n",
       "rf        0.963      0.956   0.963     0.959  0.980\n",
       "gt        0.963      0.942   0.978     0.960  0.987\n",
       "ridge     0.957      0.923   0.985     0.953  0.959\n",
       "svc       0.950      0.922   0.970     0.945  0.980\n",
       "dt        0.947      0.928   0.955     0.941  0.947\n",
       "ada       0.940      0.926   0.940     0.933  0.980\n",
       "knn       0.923      0.872   0.970     0.919  0.972"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.T.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:54:42.432970Z",
     "start_time": "2020-10-18T10:54:42.426095Z"
    }
   },
   "outputs": [],
   "source": [
    "os.mkdir('../save/notebook_classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:58:36.448546Z",
     "start_time": "2020-10-18T10:58:36.437698Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(model_name)):\n",
    "    with open(f'../save/notebook_classification/{model_name[i]}_nb_cls.pkl', 'wb') as file:\n",
    "        pickle.dump(model[i], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T11:04:32.708052Z",
     "start_time": "2020-10-18T11:04:32.700764Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_df.T.sort_values(by='Accuracy', ascending=False).to_csv('../save/notebook_classification/metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T10:58:38.702671Z",
     "start_time": "2020-10-18T10:58:38.693580Z"
    }
   },
   "outputs": [],
   "source": [
    "load_model = []\n",
    "for i in range(len(model_name)):\n",
    "    with open(f'../save/notebook_classification/{model_name[i]}_nb_cls.pkl', 'rb') as file:\n",
    "        load_model.append(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T11:02:17.696494Z",
     "start_time": "2020-10-18T11:02:17.677064Z"
    }
   },
   "outputs": [],
   "source": [
    "ols_prob = load_model[0].predict_proba(x_test)[:,1]\n",
    "ridge_prob = load_model[1].predict(x_test)\n",
    "\n",
    "dt_prob = load_model[2].predict_proba(x_test)[:,1]\n",
    "rf_prob = load_model[3].predict_proba(x_test)[:,1]\n",
    "ada_prob = load_model[4].predict_proba(x_test)[:,1]\n",
    "gt_prob = load_model[5].predict_proba(x_test)[:,1]\n",
    "\n",
    "svc_prob = load_model[6].predict_proba(x_test)[:,1]\n",
    "knn_prob = load_model[7].predict_proba(x_test)[:,1]\n",
    "\n",
    "load_prob = [ols_prob, ridge_prob, dt_prob, rf_prob, ada_prob, gt_prob, svc_prob, knn_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T11:05:01.193010Z",
     "start_time": "2020-10-18T11:05:01.148735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ols</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ridge</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>svc</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dt</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ada</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>knn</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy  Precision  Recall  F1_score    AUC\n",
       "ols       0.963      0.936   0.985     0.960  0.985\n",
       "rf        0.963      0.956   0.963     0.959  0.980\n",
       "gt        0.963      0.942   0.978     0.960  0.987\n",
       "ridge     0.957      0.923   0.985     0.953  0.959\n",
       "svc       0.950      0.922   0.970     0.945  0.980\n",
       "dt        0.947      0.928   0.955     0.941  0.947\n",
       "ada       0.940      0.926   0.940     0.933  0.980\n",
       "knn       0.923      0.872   0.970     0.919  0.972"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_eval_df = pd.DataFrame(dict([model_name[i],\n",
    "                                  model_eval(y_test, load_model[i].predict(x_test), load_prob[i])] \n",
    "                                  for i in range(len(model_name))),\n",
    "                            index=['Accuracy','Precision','Recall','F1_score','AUC'])\n",
    "load_eval_df.T.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T11:04:59.074688Z",
     "start_time": "2020-10-18T11:04:59.063234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ols</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ridge</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>svc</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ada</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>knn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy  Precision  Recall  F1_score   AUC\n",
       "ols        True       True    True      True  True\n",
       "rf         True       True    True      True  True\n",
       "gt         True       True    True      True  True\n",
       "ridge      True       True    True      True  True\n",
       "svc        True       True    True      True  True\n",
       "dt         True       True    True      True  True\n",
       "ada        True       True    True      True  True\n",
       "knn        True       True    True      True  True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_eval_df.T.sort_values(by='Accuracy', ascending=False) == eval_df.T.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
